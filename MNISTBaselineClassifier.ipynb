{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##importing dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "GzmBLH0JFgiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Digit Classification using PyTorch\n",
        "\n",
        "## Project Overview\n",
        "This project implements a complete end-to-end **multiclass image classification pipeline** using **PyTorch** on the MNIST handwritten digits dataset.\n",
        "\n",
        "The objective is to build, train, validate, and evaluate a fully connected neural network that classifies grayscale digit images (0–9) while following **standard machine learning and deep learning best practices**.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "- Multiclass classification (10 classes)\n",
        "- Clean **Train / Validation / Test** split\n",
        "- GPU acceleration (CUDA support)\n",
        "- Cross-Entropy loss with raw logits\n",
        "- Accuracy and loss tracking\n",
        "- Model checkpointing\n",
        "- Inference on unseen samples\n",
        "# MNIST Digit Classification using PyTorch\n",
        "\n",
        "## Project Overview\n",
        "This project implements a complete end-to-end **multiclass image classification pipeline** using **PyTorch** on the MNIST handwritten digits dataset.\n",
        "\n",
        "The objective is to build, train, validate, and evaluate a fully connected neural network that classifies grayscale digit images (0–9) while following **standard machine learning and deep learning best practices**.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "- Multiclass classification (10 classes)\n",
        "- Clean **Train / Validation / Test** split\n",
        "- GPU acceleration (CUDA support)\n",
        "- Cross-Entropy loss with raw logits\n",
        "- Accuracy and loss tracking\n",
        "- Model checkpointing\n",
        "- Inference on unseen samples\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "- **Dataset**: MNIST Handwritten Digits\n",
        "- **Training samples**: 60,000  \n",
        "- **Test samples**: 10,000  \n",
        "- **Image size**: 28 × 28 (grayscale)\n",
        "\n",
        "The training dataset is further split into:\n",
        "- **Training set**: 85%\n",
        "- **Validation set**: 15%\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "The model is a fully connected neural network consisting of:\n",
        "- Input layer: 784 neurons (flattened image)\n",
        "- Hidden layers:\n",
        "  - Linear(784 → 128) + ReLU\n",
        "  - Linear(128 → 64) + ReLU\n",
        "- Output layer: Linear(64 → 10)\n",
        "\n",
        "No softmax is applied inside the model.  \n",
        "`CrossEntropyLoss` internally handles softmax.\n",
        "\n",
        "---\n",
        "\n",
        "## Training Strategy\n",
        "- Optimizer: Adam\n",
        "- Learning rate: 0.001\n",
        "- Loss function: CrossEntropyLoss\n",
        "- Batch size: 64\n",
        "- Epochs: 5\n",
        "- Evaluation metrics: Loss and Accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## Project Structure\n",
        "1. Device configuration\n",
        "2. Dataset loading and preprocessing\n",
        "3. Train / validation split\n",
        "4. Model definition\n",
        "5. Training loop\n",
        "6. Validation loop\n",
        "7. Final test evaluation\n",
        "8. Inference\n",
        "9. Model saving\n",
        "\n",
        "---\n",
        "\n",
        "## Goal\n",
        "This notebook is designed to:\n",
        "- Demonstrate **real-world PyTorch workflow**\n",
        "- Follow **professional ML conventions**\n",
        "- Be suitable for **interviews, portfolios, and GitHub review**\n",
        "# MNIST Digit Classification using PyTorch\n",
        "\n",
        "## Project Overview\n",
        "This project implements a complete end-to-end **multiclass image classification pipeline** using **PyTorch** on the MNIST handwritten digits dataset.\n",
        "\n",
        "The objective is to build, train, validate, and evaluate a fully connected neural network that classifies grayscale digit images (0–9) while following **standard machine learning and deep learning best practices**.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "- Multiclass classification (10 classes)\n",
        "- Clean **Train / Validation / Test** split\n",
        "- GPU acceleration (CUDA support)\n",
        "- Cross-Entropy loss with raw logits\n",
        "- Accuracy and loss tracking\n",
        "- Model checkpointing\n",
        "- Inference on unseen samples\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "- **Dataset**: MNIST Handwritten Digits\n",
        "- **Training samples**: 60,000  \n",
        "- **Test samples**: 10,000  \n",
        "- **Image size**: 28 × 28 (grayscale)\n",
        "\n",
        "The training dataset is further split into:\n",
        "- **Training set**: 85%\n",
        "- **Validation set**: 15%\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "The model is a fully connected neural network consisting of:\n",
        "- Input layer: 784 neurons (flattened image)\n",
        "- Hidden layers:\n",
        "  - Linear(784 → 128) + ReLU\n",
        "  - Linear(128 → 64) + ReLU\n",
        "- Output layer: Linear(64 → 10)\n",
        "\n",
        "No softmax is applied inside the model.  \n",
        "`CrossEntropyLoss` internally handles softmax.\n",
        "\n",
        "---\n",
        "\n",
        "## Training Strategy\n",
        "- Optimizer: Adam\n",
        "- Learning rate: 0.001\n",
        "- Loss function: CrossEntropyLoss\n",
        "- Batch size: 64\n",
        "- Epochs: 5\n",
        "- Evaluation metrics: Loss and Accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## Project Structure\n",
        "1. Device configuration\n",
        "2. Dataset loading and preprocessing\n",
        "3. Train / validation split\n",
        "4. Model definition\n",
        "5. Training loop\n",
        "6. Validation loop\n",
        "7. Final test evaluation\n",
        "8. Inference\n",
        "9. Model saving\n",
        "\n",
        "---\n",
        "\n",
        "## Goal\n",
        "This notebook is designed to:\n",
        "- Demonstrate **real-world PyTorch workflow**\n",
        "- Follow **professional ML conventions**\n",
        "- Be suitable for **interviews, portfolios, and GitHub review**\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "- **Dataset**: MNIST Handwritten Digits\n",
        "- **Training samples**: 60,000  \n",
        "- **Test samples**: 10,000  \n",
        "- **Image size**: 28 × 28 (grayscale)\n",
        "\n",
        "The training dataset is further split into:\n",
        "- **Training set**: 85%\n",
        "- **Validation set**: 15%\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "The model is a fully connected neural network consisting of:\n",
        "- Input layer: 784 neurons (flattened image)\n",
        "- Hidden layers:\n",
        "  - Linear(784 → 128) + ReLU\n",
        "  - Linear(128 → 64) + ReLU\n",
        "- Output layer: Linear(64 → 10)\n",
        "\n",
        "No softmax is applied inside the model.  \n",
        "`CrossEntropyLoss` internally handles softmax.\n",
        "\n",
        "---\n",
        "\n",
        "## Training Strategy\n",
        "- Optimizer: Adam\n",
        "- Learning rate: 0.001\n",
        "- Loss function: CrossEntropyLoss\n",
        "- Batch size: 64\n",
        "- Epochs: 5\n",
        "- Evaluation metrics: Loss and Accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## Project Structure\n",
        "1. Device configuration\n",
        "2. Dataset loading and preprocessing\n",
        "3. Train / validation split\n",
        "4. Model definition\n",
        "5. Training loop\n",
        "6. Validation loop\n",
        "7. Final test evaluation\n",
        "8. Inference\n",
        "9. Model saving\n",
        "\n",
        "---\n",
        "\n",
        "## Goal\n",
        "This notebook is designed to:\n",
        "- Demonstrate **real-world PyTorch workflow**\n",
        "- Follow **professional ML conventions**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eo91sDwKKqGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##device selection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n"
      ],
      "metadata": {
        "id": "rrR9SWVFO7yL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59d7a8d-5bb5-4e1e-960b-7aaa5de737f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device Configuration\n",
        "\n",
        "This project supports both **CPU and GPU (CUDA)** execution.\n",
        "\n",
        "If a CUDA-enabled GPU is available, the model and data are moved to the GPU to accelerate training and inference. Otherwise, the code falls back to CPU execution.\n",
        "\n",
        "Explicit device handling ensures:\n",
        "- Hardware-independent execution\n",
        "- Faster training on supported systems\n",
        "- Correct tensor placement during computation\n"
      ],
      "metadata": {
        "id": "QsGf_7UjO5XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Dataset and dataloader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "full_train_data = MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XcM5zeRHr-d",
        "outputId": "0dc21b3a-d2cb-4b48-e37e-e7683ad896ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 343kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.21MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading & Preprocessing\n",
        "\n",
        "The MNIST dataset consists of grayscale images of handwritten digits (0–9), each of size 28×28 pixels.\n",
        "\n",
        "Images are preprocessed using:\n",
        "- `ToTensor()` to convert images into PyTorch tensors\n",
        "- `Normalize()` to standardize pixel values using the dataset mean and standard deviation\n",
        "\n",
        "Normalization helps stabilize and speed up training by ensuring that input features are on a similar scale, which improves gradient-based optimization.\n",
        "\n",
        "## DataLoaders\n",
        "\n",
        "PyTorch DataLoaders are used to:\n",
        "- Load data in mini-batches\n",
        "- Shuffle training data to improve generalization\n",
        "- Ensure efficient iteration during training and evaluation\n",
        "\n",
        "Shuffling is enabled only for the training set and disabled for validation and test sets.\n"
      ],
      "metadata": {
        "id": "I7WeYKOAPD_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train / Validation split\n",
        "train_size = int(0.85 * len(full_train_data))\n",
        "val_size = len(full_train_data) - train_size\n",
        "\n",
        "train_data, val_data = random_split(\n",
        "    full_train_data, [train_size, val_size]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_data,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "d8uZ28WFINIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train / Validation / Test Split\n",
        "\n",
        "The original MNIST training dataset is split into:\n",
        "- **Training set (85%)** for learning model parameters\n",
        "- **Validation set (15%)** for tuning and monitoring performance\n",
        "\n",
        "The official MNIST test set is kept completely separate and is used only for final evaluation to ensure unbiased results.\n"
      ],
      "metadata": {
        "id": "vKyopK1FPN6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Model Creation\n",
        "class DigitModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = DigitModel().to(device)"
      ],
      "metadata": {
        "id": "i36qDoPSIS2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "\n",
        "The model is a fully connected neural network with:\n",
        "- Input layer of 784 units (flattened 28×28 image)\n",
        "- Two hidden layers with ReLU activation\n",
        "- Output layer with 10 units corresponding to digit classes (0–9)\n",
        "\n",
        "No softmax layer is applied inside the model, as the loss function handles it internally.\n"
      ],
      "metadata": {
        "id": "muPpnz_cPhuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "QMoE2wi2Idcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function & Optimizer\n",
        "\n",
        "- **Loss Function**: CrossEntropyLoss, suitable for multiclass classification with integer class labels\n",
        "- **Optimizer**: Adam, chosen for its adaptive learning rate and stable convergence\n",
        "\n",
        "The model outputs raw logits, which are directly passed to the loss function.\n"
      ],
      "metadata": {
        "id": "RJJSKQEXPnx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Training loop and Validation loop\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # ---------- TRAIN ----------\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = loss_fn(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        train_correct += (preds == yb).sum().item()\n",
        "        train_total += yb.size(0)\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    # ---------- VALIDATION ----------\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "\n",
        "            xb = xb.view(xb.size(0), -1)\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            val_correct += (preds == yb).sum().item()\n",
        "            val_total += yb.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1:03d} | \"\n",
        "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Val Acc: {val_acc:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1wzkq47IpvZ",
        "outputId": "ae036857-d571-4910-ff92-b1196384a5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train Loss: 0.2889 | Train Acc: 0.9140 | Val Loss: 0.1492 | Val Acc: 0.9549\n",
            "Epoch 002 | Train Loss: 0.1217 | Train Acc: 0.9629 | Val Loss: 0.1018 | Val Acc: 0.9710\n",
            "Epoch 003 | Train Loss: 0.0846 | Train Acc: 0.9734 | Val Loss: 0.0836 | Val Acc: 0.9756\n",
            "Epoch 004 | Train Loss: 0.0653 | Train Acc: 0.9794 | Val Loss: 0.0857 | Val Acc: 0.9739\n",
            "Epoch 005 | Train Loss: 0.0504 | Train Acc: 0.9842 | Val Loss: 0.1019 | Val Acc: 0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Results\n",
        "\n",
        "The model shows consistent convergence across epochs, with decreasing training and validation loss and stable validation accuracy.  \n",
        "This indicates effective learning without signs of overfitting for the chosen architecture and training setup.\n"
      ],
      "metadata": {
        "id": "sLElzeSGQN_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Final Test Evaluation\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        logits = model(xb)\n",
        "        loss = loss_fn(logits, yb)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        test_correct += (preds == yb).sum().item()\n",
        "        test_total += yb.size(0)\n",
        "\n",
        "print(\n",
        "    f\"Final Test Loss: {test_loss / len(test_loader):.4f} | \"\n",
        "    f\"Test Acc: {test_correct / test_total:.4f}\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrcgYj53IzJG",
        "outputId": "e4029d86-382f-4989-c0a8-682dfd651a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Loss: 0.0997 | Test Acc: 0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Test Evaluation\n",
        "\n",
        "The trained model is evaluated on the held-out test set that was not used during training or validation.  \n",
        "This metric represents the model’s true generalization performance on unseen data.\n",
        "**Result:**  \n",
        "The model achieves approximately 97% accuracy on the MNIST test set, indicating good generalization to unseen data.\n"
      ],
      "metadata": {
        "id": "nuXYDOYLQYbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample, _ = test_data[0]\n",
        "    sample = sample.view(1, -1).to(device)\n",
        "\n",
        "    logits = model(sample)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    prediction = torch.argmax(probs, dim=1)\n",
        "\n",
        "print(\"Probabilities:\", probs)\n",
        "print(\"Predicted digit:\", prediction.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi6iPwIRI8wx",
        "outputId": "40c4d5bb-a638-4116-8359-4f9d7c22e759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities: tensor([[2.9807e-09, 4.0808e-10, 1.2765e-06, 2.2895e-06, 5.7904e-14, 2.0114e-09,\n",
            "         8.4575e-15, 1.0000e+00, 3.0197e-09, 4.3764e-08]])\n",
            "Predicted digit: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Saving the model\n",
        "torch.save(model.state_dict(), \"mnist_model.pth\")"
      ],
      "metadata": {
        "id": "9eKl0B4KJGlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "A fully connected neural network was trained and evaluated on the MNIST dataset.  \n",
        "The model achieves stable training and validation performance on the MNIST dataset using a simple fully connected architecture.\n",
        "\n",
        "The model demonstrates stable training behavior and achieves approximately 97% accuracy on unseen test data.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kma2N20gP09a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations & Future Improvements\n",
        "\n",
        "While the fully connected network performs reasonably well, convolutional neural networks (CNNs) are better suited for image data.\n",
        "\n",
        "Future improvements could include:\n",
        "- Using CNN-based architectures\n",
        "- Adding regularization techniques\n",
        "- Experimenting with learning rate schedules"
      ],
      "metadata": {
        "id": "TDWagXTyJ61f"
      }
    }
  ]
}